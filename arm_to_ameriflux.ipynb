{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a496d902",
   "metadata": {},
   "source": [
    "# ARM to Ameriflux Code\n",
    "This code is designed presently to take data from the ARM datastream and convert it into the variables and units that Ameriflux requires for submission to their platform. Presently, if the code is ran from the command line, it will just use what is hardcoded into the script, but future updates will take date, site name and site ID from the command line to pull data for different sites. The paths for data to be saved are specific to the computer the code is being written on. For the code to be ran, a .json file must be made containing your ARM username and token. For example the token.json file should look like\n",
    "\n",
    "{\n",
    "\n",
    "\t\"username\":\"yourusername\",\n",
    "\t\"token\":\"giventokenidhere\"\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "The beginning sections of this code were written by Adam Theisen and modified to to include more data and softcode sections. Original code can be found here (https://github.com/mtuftedal/ARM-to-Ameriflux/blob/main/arm_to_ameriflux.py)\n",
    "\n",
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff484a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import xarray as xr\n",
    "import glob\n",
    "import act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adc798",
   "metadata": {},
   "source": [
    "Now you will need the .json token to use the next section of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8717edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ARM Live Data Webservice Token and Username\n",
    "with open('./token.json') as f:\n",
    "    data = json.load(f)\n",
    "username = data['username']\n",
    "token = data['token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769fb74",
   "metadata": {},
   "source": [
    "This section currently has the facility name, data_type, instruments, date hardcoded but eventually will have it softcoded and user defined if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb54b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the facility and instruments to use\n",
    "facs = ['E39']\n",
    "site_ID = str(facs[0])\n",
    "site_name = 'sgp'\n",
    "\n",
    "data_type = '.b1'\n",
    "\n",
    "# Instrument being used.\n",
    "datastreams = ['ecorsf', 'sebs', 'amc', 'stamp', 'stamppcp', ]\n",
    "\n",
    "# Set dates, first one is to use for downloading data, second is ARM format\n",
    "date = '2020-07-10'\n",
    "sdate = ''.join(date.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a2762",
   "metadata": {},
   "source": [
    "# Pulling the data\n",
    "Now we will be accessing the ARM datastream and pulling the data we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058eee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in facs:\n",
    "    ecor = None\n",
    "    sebs = None\n",
    "    amc = None\n",
    "    obj = []\n",
    "\n",
    "    # Look for ECOR data, download if None, and read in\n",
    "    ecor_files = glob.glob('./'+site_name+'ecorsf' +\n",
    "                           f + data_type + '/*' + sdate + '*')\n",
    "    if len(ecor_files) == 0:\n",
    "        ecor_files = act.discovery.download_data(\n",
    "            username, token, site_name + 'ecorsf' + f + data_type, date, date)\n",
    "    if len(ecor_files) > 0:\n",
    "        ecor = act.io.armfiles.read_netcdf(ecor_files)\n",
    "        ecor = ecor.rename({'time_bounds': 'time_bounds_ecor'})\n",
    "        # Add to object for merging datasets at the end\n",
    "        obj.append(ecor)\n",
    "\n",
    "    # Look for SEBS data, download if None, and read in\n",
    "    sebs_files = glob.glob('./'+site_name+'sebs' + f +\n",
    "                           data_type+'/*' + sdate + '*')\n",
    "    if len(sebs_files) == 0:\n",
    "        sebs_files = act.discovery.download_data(\n",
    "            username, token, site_name+'sebs' + f + data_type, date, date)\n",
    "    if len(sebs_files) > 0:\n",
    "        sebs = act.io.armfiles.read_netcdf(sebs_files)\n",
    "        obj.append(sebs)\n",
    "\n",
    "    # Look for AMC data, download if None, and read in\n",
    "    amc_files = glob.glob('./'+site_name+'amc' + f +\n",
    "                          data_type+'/*' + sdate + '*')\n",
    "    if len(amc_files) == 0:\n",
    "        amc_files = act.discovery.download_data(\n",
    "            username, token, site_name+'amc' + f + data_type, date, date)\n",
    "    if len(amc_files) > 0:\n",
    "        amc = act.io.armfiles.read_netcdf(amc_files)\n",
    "        amc = amc.rename({'time_bounds': 'time_bounds_amc'})\n",
    "        obj.append(amc)\n",
    "\n",
    "    # Look for STAMP data, download if None, and read in\n",
    "    stamp_files = glob.glob('./'+site_name+'stamp' +\n",
    "                            f + data_type+'/*' + sdate + '*')\n",
    "    if len(stamp_files) == 0:\n",
    "        stamp_files = act.discovery.download_data(\n",
    "            username, token, site_name+'stamp' + f + data_type, date, date)\n",
    "    if len(stamp_files) > 0:\n",
    "        stamp = act.io.armfiles.read_netcdf(stamp_files)\n",
    "        obj.append(stamp)\n",
    "\n",
    "    # Look for STAMPPCP data, download if None, and read in\n",
    "    stamppcp_files = glob.glob(\n",
    "        './'+site_name+'stamppcp' + f + data_type+'/*' + sdate + '*')\n",
    "    if len(stamppcp_files) == 0:\n",
    "        stamppcp_files = act.discovery.download_data(\n",
    "            username, token, site_name+'stamppcp' + f + data_type, date, date)\n",
    "    if len(stamppcp_files) > 0:\n",
    "        stamppcp = act.io.armfiles.read_netcdf(stamppcp_files)\n",
    "        stamppcp = stamppcp.resample(time='30T').mean()\n",
    "        obj.append(stamppcp)\n",
    "\n",
    "    # Merge 4 instruments together into one xarray object\n",
    "    obj = xr.merge(obj, compat='override')\n",
    "\n",
    "    # Close out individual objects\n",
    "    ecor.close()\n",
    "    sebs.close()\n",
    "    amc.close()\n",
    "    stamp.close()\n",
    "    stamppcp.close()\n",
    "\n",
    "    # Create dirs and write out merged data\n",
    "    if not os.path.exists('./'+site_name+'flux' + f + data_type+'/'):\n",
    "        os.mkdir('./'+site_name+'flux' + f + data_type+'/')\n",
    "    obj.to_netcdf('./'+site_name+'flux' + f + data_type+'/' +\n",
    "                  site_name+'flux' + f + data_type + sdate + '.000000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a374c",
   "metadata": {},
   "source": [
    "# Selecting the Ameriflux ID from site IDs and renaming variables\n",
    "Now that we have the data downloaded and everything merged into one file. It is now time to extract the variables that are accepted into the Ameriflux system and rename them from the ARM naming convention to the Ameriflux convention. \n",
    "\n",
    "First we will start by changing the site location and ID into the Ameriflux naming convention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba36f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the correct Ameriflux Site name based on location.\n",
    "# Central Facility, Lamont, OK\n",
    "if (site_name == 'sgp' and site_ID == 'C1'):\n",
    "    Ameriflux_name = 'US-A14'\n",
    "# Newkirk, OK (Extended)\n",
    "elif (site_name == 'sgp' and site_ID == 'E33'):\n",
    "    Ameriflux_name = 'US-A33'\n",
    "# Waukomis, OK (Extended)\n",
    "elif (site_name == 'sgp' and site_ID == 'E37'):\n",
    "    Ameriflux_name = 'US-A37'\n",
    "# Morrison, OK (Extended)\n",
    "elif (site_name == 'sgp' and site_ID == 'E39'):\n",
    "    Ameriflux_name = 'US-A39'\n",
    "# Peckham, OK (Extended)\n",
    "elif (site_name == 'sgp' and site_ID == 'E41'):\n",
    "    Ameriflux_name = 'US-A41'\n",
    "\n",
    "# Barrow, AK\n",
    "elif site_name == 'nsa' and site_ID == 'C1':\n",
    "    Ameriflux_name = 'US-A10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c168002",
   "metadata": {},
   "source": [
    "Now we will pull the data from the location machine. This will be changed with later iterations of the code and should be changed on your local computer to match it's location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76818eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLUX_path = (r'Z:/Matt/virtual_machine_shared/Ameriflux/' +\n",
    "             site_name+'fluxE39'+data_type+'/')\n",
    "FLUX_files = os.listdir(FLUX_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18bdf8",
   "metadata": {},
   "source": [
    "Now for the majority of the work to be done. This for loop encompasses all of the data and work needed to be done within the files. This can eventually be edited to remove the loop and just take one singular file, but right now it is set to run as if there would be more than one day to process. It could be modified to call the file name from the the given date later. \n",
    "\n",
    "First we are taking the file from the sort path and extracting the netCDF file into an xarray data set. Then the time variables are extracted to create start and stop time bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d936154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in sorted(FLUX_files):\n",
    "    fpath_FLUX = os.path.join(FLUX_path, files)\n",
    "    ds = xr.open_dataset(fpath_FLUX, engine='netcdf4')\n",
    "\n",
    "    # Setting up time bounds and created an array of formatted times to\n",
    "    # meet Ameriflux standard.\n",
    "    time_bounds = ds['time_bounds_ecor'].dt.strftime(\"%Y%m%d%H%M\")\n",
    "    time_start = time_bounds\n",
    "    TIMESTAMP_START = np.array([])\n",
    "    TIMESTAMP_END = np.array([])\n",
    "    for i in range(len(time_bounds)):\n",
    "        start = time_bounds[i][0]\n",
    "        end = time_bounds[i][1]\n",
    "        TIMESTAMP_START = np.append(TIMESTAMP_START, start)\n",
    "        TIMESTAMP_END = np.append(TIMESTAMP_END, end)\n",
    "\n",
    "    # Adding variable and renaming it in xarray\n",
    "    TIMESTAMP_START = xr.DataArray(TIMESTAMP_START, dims='time')\n",
    "    TIMESTAMP_START = TIMESTAMP_START.rename(\"TIMESTAMP_START\")\n",
    "    TIMESTAMP_END = xr.DataArray(TIMESTAMP_END, dims='time')\n",
    "    TIMESTAMP_END = TIMESTAMP_END.rename(\"TIMESTAMP_END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a3e30",
   "metadata": {},
   "source": [
    "First we will be looking at the variables from the ECORSF sensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9d2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Carbon Dioxide (CO2) turbulent flux (no storage correction)\n",
    "    try:\n",
    "        FC = ds['co2_flux'].rename(\"FC\")\n",
    "    except KeyError:\n",
    "        FC = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        FC = xr.DataArray(FC, dims='time')\n",
    "        FC = FC.rename(\"FC\")\n",
    "\n",
    "    # Methane (CH4) turbulent flux (no storage correction)\n",
    "    # FCH4 Not in our data\n",
    "\n",
    "    # Carbon Dioxide (CO2) mole fraction in wet air\n",
    "    try:\n",
    "        CO2 = ds['co2_molar_fraction'].rename(\"CO2\")\n",
    "    except KeyError:\n",
    "        CO2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        CO2 = xr.DataArray(CO2, dims='time')\n",
    "        CO2 = CO2.rename(\"CO2\")\n",
    "\n",
    "    # Carbon Dioxide (CO2) in mole fraction of dry air\n",
    "    try:\n",
    "        CO2_MIXING_RATIO = ds['co2_mixing_ratio'].rename(\"CO2_MIXING_RATIO\")\n",
    "\n",
    "    except KeyError:\n",
    "        CO2_MIXING_RATIO = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        CO2_MIXING_RATIO = xr.DataArray(CO2_MIXING_RATIO, dims='time')\n",
    "        CO2_MIXING_RATIO = CO2_MIXING_RATIO.rename(\"CO2_MIXING_RATIO\")\n",
    "\n",
    "    # Water (H2O) vapor in mole fraction of wet air\n",
    "    try:\n",
    "        H2O = ds['h2o_molar_fraction'].rename(\"H20\")\n",
    "    except KeyError:\n",
    "        H2O = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        H2O = xr.DataArray(H2O, dims='time')\n",
    "        H2O = H2O.rename(\"H2O\")\n",
    "\n",
    "    # Water (H2O) vapor in mole fraction of dry air\n",
    "    try:\n",
    "        H2O_MIXING_RATIO = ds['h2o_mixing_ratio'].rename(\"H2O_MIXING_RATIO\")\n",
    "    except KeyError:\n",
    "        H2O_MIXING_RATIO = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        H2O_MIXING_RATIO = xr.DataArray(H2O_MIXING_RATIO, dims='time')\n",
    "        H2O_MIXING_RATIO = H2O_MIXING_RATIO.rename(\"H2O_MIXING_RATIO\")\n",
    "\n",
    "    # Methane (CH4) mole fraction in wet air\n",
    "    try:\n",
    "        CH4 = ds['ch4_molar_fraction'].rename(\"CH4\")\n",
    "    except KeyError:\n",
    "        CH4 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        CH4 = xr.DataArray(CH4, dims='time')\n",
    "        CH4 = CH4.rename(\"CH4\")\n",
    "\n",
    "    # Methane (CH4) in mole fraction of dry air\n",
    "    try:\n",
    "        CH4_MIXING_RATIO = ds['ch4_mixing_ratio'].rename(\"CH4_MIXING_RATIO\")\n",
    "    except KeyError:\n",
    "        CH4_MIXING_RATIO = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        CH4_MIXING_RATIO = xr.DataArray(CH4_MIXING_RATIO, dims='time')\n",
    "        CH4_MIXING_RATIO = CH4_MIXING_RATIO.rename(\"CH4_MIXING_RATIO\")\n",
    "\n",
    "    # Momentum flux\n",
    "    try:\n",
    "        TAU = ds['momentum_flux'].rename(\"TAU\")\n",
    "    except KeyError:\n",
    "        TAU = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TAU = xr.DataArray(TAU, dims='time')\n",
    "        TAU = TAU.rename(\"TAU\")\n",
    "\n",
    "    # Sensible heat turbulent flux (no storage correction)\n",
    "    try:\n",
    "        H = ds['sensible_heat_flux'].rename(\"H\")\n",
    "    except KeyError:\n",
    "        H = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        H = xr.DataArray(H, dims='time')\n",
    "        H = H.rename(\"H\")\n",
    "\n",
    "    # Latent heat turbulent flux (no storage correction)\n",
    "    try:\n",
    "        LE = ds['latent_flux'].rename(\"LE\")\n",
    "    except KeyError:\n",
    "        LE = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        LE = xr.DataArray(LE, dims='time')\n",
    "        LE = LE.rename(\"LE\")\n",
    "\n",
    "    # Air temperature given in K then converted to degC\n",
    "    try:\n",
    "        TA = ds['air_temperature'].rename(\"TA\")\n",
    "        TA = TA-273.15\n",
    "    except KeyError:\n",
    "        TA = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TA = xr.DataArray(TA, dims='time')\n",
    "        TA = TA.rename(\"TA\")\n",
    "\n",
    "    # Atmospheric pressure\n",
    "    try:\n",
    "        PA = ds['air_pressure'].rename(\"PA\")\n",
    "    except KeyError:\n",
    "        PA = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        PA = xr.DataArray(PA, dims='time')\n",
    "        PA = PA.rename(\"PA\")\n",
    "\n",
    "    # Relative humidity, range 0-100\n",
    "    try:\n",
    "        RH = ds['relative_humidity'].rename(\"RH\")\n",
    "    except KeyError:\n",
    "        RH = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        RH = xr.DataArray(RH, dims='time')\n",
    "        RH = RH.rename(\"RH\")\n",
    "\n",
    "    # Sonic temperature\n",
    "    try:\n",
    "        T_SONIC = ds['sonic_temperature'].rename(\"T_SONIC\")\n",
    "        T_SONIC = T_SONIC-273.15\n",
    "    except KeyError:\n",
    "        T_SONIC = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        T_SONIC = xr.DataArray(T_SONIC, dims='time')\n",
    "        T_SONIC = T_SONIC.rename(\"T_SONIC\")\n",
    "\n",
    "    # Vapor Pressure Deficit and is converted to hPa from kPa\n",
    "    try:\n",
    "        VPD = ds['water_vapor_pressure_deficit'].rename(\"VPD\")\n",
    "        VPD = VPD*10\n",
    "    except KeyError:\n",
    "        VPD = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        VPD = xr.DataArray(VPD, dims='time')\n",
    "        VPD = VPD.rename(\"VPD\")\n",
    "\n",
    "    # Monin-Obukhov length\n",
    "    try:\n",
    "        MO_LENGTH = ds['Monin_Obukhov_length'].rename(\"MO_LENGTH\")\n",
    "    except KeyError:\n",
    "        MO_LENGTH = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        MO_LENGTH = xr.DataArray(MO_LENGTH, dims='time')\n",
    "        MO_LENGTH = MO_LENGTH.rename(\"MO_LEGNTH\")\n",
    "\n",
    "    # Monin-Obukhov Stability parameter\n",
    "    try:\n",
    "        ZL = ds['Monin_Obukhov_stability_parameter'].rename(\"ZL\")\n",
    "    except KeyError:\n",
    "        ZL = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        ZL = xr.DataArray(ZL, dims='time')\n",
    "        ZL = ZL.rename(\"ZL\")\n",
    "\n",
    "    # Wind speed\n",
    "    try:\n",
    "        WS = ds['mean_wind'].rename(\"WS\")\n",
    "    except KeyError:\n",
    "        WS = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        WS = xr.DataArray(WS, dims='time')\n",
    "        WS = WS.rename(\"WS\")\n",
    "\n",
    "    # Wind direction\n",
    "    try:\n",
    "        WD = ds['wind_direction_from_north'].rename(\"WD\")\n",
    "    except KeyError:\n",
    "        WD = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        WD = xr.DataArray(WD, dims='time')\n",
    "        WD = WD.rename(\"WD\")\n",
    "\n",
    "    # Friction velocity\n",
    "    try:\n",
    "        USTAR = ds['friction_velocity'].rename(\"USTAR\")\n",
    "    except KeyError:\n",
    "        USTAR = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        USTAR = xr.DataArray(USTAR, dims='time')\n",
    "        USTAR = USTAR.rename(\"USTAR\")\n",
    "\n",
    "    # Maximum WS in the averaging period\n",
    "    try:\n",
    "        WS_MAX = ds['maximum_instantaneous_wind_speed'].rename(\"WS_MAX\")\n",
    "    except KeyError:\n",
    "        WS_MAX = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        WS_MAX = xr.DataArray(WS_MAX, dims='time')\n",
    "        WS_MAX = WS_MAX.rename(\"WS_MAX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4fd4d",
   "metadata": {},
   "source": [
    "Now for the SEBS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7e40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Shortwave radiation, incoming\n",
    "    try:\n",
    "        SW_IN = ds['down_short_hemisp'].rename('SW_IN')\n",
    "    except:\n",
    "        SW_IN = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SW_IN = xr.DataArray(SW_IN, dims='time')\n",
    "        SW_IN = SW_IN.rename(\"SW_IN\")\n",
    "\n",
    "    # Shortwave radiation, outgoing\n",
    "    try:\n",
    "        SW_OUT = ds['up_short_hemisp'].rename(\"SW_OUT\")\n",
    "    except:\n",
    "        SW_OUT = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SW_OUT = xr.DataArray(SW_OUT, dims='time')\n",
    "        SW_OUT = SW_OUT.rename(\"SW_OUT\")\n",
    "\n",
    "    # Longwave radiation, incoming\n",
    "    try:\n",
    "        LW_IN = ds['down_long'].rename(\"LW_IN\")\n",
    "    except:\n",
    "        LW_IN = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        LW_IN = xr.DataArray(LW_IN, dims='time')\n",
    "        LW_IN = H2O.rename(\"LW_IN\")\n",
    "\n",
    "    # Longwave radiation, outgoing\n",
    "    try:\n",
    "        LW_OUT = ds['up_long'].rename(\"LW_OUT\")\n",
    "    except:\n",
    "        LW_OUT = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        LW_OUT = xr.DataArray(LW_OUT, dims='time')\n",
    "        LW_OUT = LW_OUT.rename(\"LW_OUT\")\n",
    "\n",
    "    # Albedo, range 0-100\n",
    "    try:\n",
    "        ALB = ds['albedo'].rename(\"ALB\")\n",
    "    except:\n",
    "        ALB = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        ALB = xr.DataArray(ALB, dims='time')\n",
    "        ALB = ALB.rename(\"ALB\")\n",
    "\n",
    "    # Net radiation\n",
    "    try:\n",
    "        NETRAD = ds['net_radiation'].rename(\"NETRAD\")\n",
    "    except:\n",
    "        NETRAD = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        NETRAD = xr.DataArray(NETRAD, dims='time')\n",
    "        NETRAD = NETRAD.rename(\"NETRAD\")\n",
    "\n",
    "# Soil heat flux\n",
    "    try:\n",
    "        G_1_1_1 = ds['surface_soil_heat_flux_1'].rename(\"G_1_1_1\")\n",
    "    except KeyError:\n",
    "        G_1_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        G_1_1_1 = xr.DataArray(G_1_1_1, dims='time')\n",
    "        G_1_1_1 = G_1_1_1.rename(\"G_1_1_1\")\n",
    "\n",
    "    # Soil heat flux\n",
    "    try:\n",
    "        G_1_1_2 = ds['surface_soil_heat_flux_2'].rename(\"G_1_1_2\")\n",
    "    except KeyError:\n",
    "        G_1_1_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        G_1_1_2 = xr.DataArray(G_1_1_2, dims='time')\n",
    "        G_1_1_2 = G_1_1_2.rename(\"G_1_1_2\")\n",
    "\n",
    "    # Soil heat flux\n",
    "    try:\n",
    "        G_1_1_3 = ds['surface_soil_heat_flux_3'].rename(\"G_1_1_3\")\n",
    "    except KeyError:\n",
    "        G_1_1_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        G_1_1_3 = xr.DataArray(G_1_1_3, dims='time')\n",
    "        G_1_1_3 = G_1_1_3.rename(\"G_1_1_3\")\n",
    "\n",
    "    # Soil heat flux average. Variable is tested to ensure no missing value\n",
    "    # codes skew the averaging.Two data points are pulled to make sure data\n",
    "    # exists in the file.\n",
    "    count = 0\n",
    "    if G_1_1_1[0] != -9999 and G_1_1_1[30] != -9999:\n",
    "        G_1_1_1 = G_1_1_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        G_1_1_1_1 = G_1_1_1*0\n",
    "\n",
    "    if G_1_1_2[0] != -9999 and G_1_1_2[30] != -9999:\n",
    "        G_1_1_2 = G_1_1_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        G_1_1_2 = G_1_1_2*0\n",
    "\n",
    "    if G_1_1_3[0] != -9999 and G_1_1_3[30] != -9999:\n",
    "        G_1_1_3 = G_1_1_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        G_1_1_3 = G_1_1_3*0\n",
    "\n",
    "    G_1_1_A = (G_1_1_1 + G_1_1_2 + G_1_1_3)/count\n",
    "    G_1_1_A = G_1_1_A.rename(\"G_1_1_A\")\n",
    "\n",
    "    # Soil temperature\n",
    "    try:\n",
    "        TS_1_1_1 = ds['soil_temp_1'].rename(\"TS_1_1_1\")\n",
    "    except KeyError:\n",
    "        TS_1_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_1_1_1 = xr.DataArray(TS_1_1_1, dims='time')\n",
    "        TS_1_1_1 = TS_1_1_1.rename(\"TS_1_1_1\")\n",
    "\n",
    "    # Soil temperature\n",
    "    try:\n",
    "        TS_1_1_2 = ds['soil_temp_2'].rename(\"TS_1_1_2\")\n",
    "    except KeyError:\n",
    "        TS_1_1_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_1_1_2 = xr.DataArray(TS_1_1_2, dims='time')\n",
    "        TS_1_1_2 = TS_1_1_2.rename(\"TS_1_1_2\")\n",
    "\n",
    "    # Soil temperature\n",
    "    try:\n",
    "        TS_1_1_3 = ds['soil_temp_3'].rename(\"TS_1_1_3\")\n",
    "    except KeyError:\n",
    "        TS_1_1_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_1_1_3 = xr.DataArray(TS_1_1_3, dims='time')\n",
    "        TS_1_1_3 = TS_1_1_3.rename(\"TS_1_1_3\")\n",
    "\n",
    "    # Soil temperature average. Variables are tested to verify they exist\n",
    "    # and ensure no missing value codes skew the data.\n",
    "    count = 0\n",
    "    if TS_1_1_1[0] != -9999 and TS_1_1_1[30] != -9999:\n",
    "        TS_1_1_1 = TS_1_1_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_1_1_1 = TS_1_1_1*0\n",
    "\n",
    "    if TS_1_1_2[0] != -9999 and TS_1_1_2[30] != -9999:\n",
    "        TS_1_1_2 = TS_1_1_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_1_1_2 = TS_1_1_2*0\n",
    "\n",
    "    if TS_1_1_3[0] != -9999 and TS_1_1_3[30] != -9999:\n",
    "        TS_1_1_3 = TS_1_1_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_1_1_3 = TS_1_1_3*0\n",
    "\n",
    "    # Averages out the soil temperature based on number of non missing\n",
    "    # value data given in the array.\n",
    "    TS_1_1_A = (TS_1_1_1 + TS_1_1_2 + TS_1_1_3)/count\n",
    "    TS_1_1_A = TS_1_1_A.rename(\"TS_1_1_A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e032343",
   "metadata": {},
   "source": [
    "AMC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d02209",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Soil Temperature from AMC probe depth -36.8 cm.\n",
    "    try:\n",
    "        TS_2_2_1 = ds['temp_1'].rename(\"TS_2_2_1\")\n",
    "    except KeyError:\n",
    "        TS_2_2_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_1 = xr.DataArray(TS_2_2_1, dims='time')\n",
    "        TS_2_2_1 = TS_2_2_1.rename(\"TS_2_2_1\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -14 cm.\n",
    "    try:\n",
    "        TS_2_1_1 = ds['temp_2'].rename(\"TS_2_1_1\")\n",
    "    except KeyError:\n",
    "        TS_2_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_1 = xr.DataArray(TS_2_1_1, dims='time')\n",
    "        TS_2_1_1 = TS_2_1_1.rename(\"TS_2_1_1\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -35.6 cm\n",
    "    try:\n",
    "        TS_2_2_2 = ds['temp_3'].rename(\"TS_2_2_2\")\n",
    "    except KeyError:\n",
    "        TS_2_2_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_2 = xr.DataArray(TS_2_2_2, dims='time')\n",
    "        TS_2_2_2 = TS_2_2_2.rename(\"TS_2_2_2\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -14 cm\n",
    "    try:\n",
    "        TS_2_1_2 = ds['temp_4'].rename(\"TS_2_1_2\")\n",
    "    except KeyError:\n",
    "        TS_2_1_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_2 = xr.DataArray(TS_2_1_2, dims='time')\n",
    "        TS_2_1_2 = TS_2_1_2.rename(\"TS_2_1_2\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -35.6 cm\n",
    "    try:\n",
    "        TS_2_2_3 = ds['temp_5'].rename(\"TS_2_2_3\")\n",
    "    except KeyError:\n",
    "        TS_2_2_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_3 = xr.DataArray(TS_2_2_3, dims='time')\n",
    "        TS_2_2_3 = TS_2_2_3.rename(\"TS_2_2_3\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -14 cm\n",
    "    try:\n",
    "        TS_2_1_3 = ds['temp_6'].rename(\"TS_2_1_3\")\n",
    "    except KeyError:\n",
    "        TS_2_1_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_3 = xr.DataArray(TS_2_1_3, dims='time')\n",
    "        TS_2_1_3 = TS_2_1_3.rename(\"TS_2_1_3\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -34.3 cm\n",
    "    try:\n",
    "        TS_2_2_4 = ds['temp_7'].rename(\"TS_2_2_4\")\n",
    "    except KeyError:\n",
    "        TS_2_2_4 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_4 = xr.DataArray(TS_2_2_4, dims='time')\n",
    "        TS_2_2_4 = TS_2_2_4.rename(\"TS_2_2_4\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -15.2 cm\n",
    "    try:\n",
    "        TS_2_1_4 = ds['temp_8'].rename(\"TS_2_1_4\")\n",
    "    except KeyError:\n",
    "        TS_2_1_4 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_4 = xr.DataArray(TS_2_1_4, dims='time')\n",
    "        TS_2_1_4 = TS_2_1_4.rename(\"TS_2_1_4\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -34.9\n",
    "    try:\n",
    "        TS_2_2_5 = ds['temp_9'].rename(\"TS_2_2_5\")\n",
    "    except KeyError:\n",
    "        TS_2_2_5 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_5 = xr.DataArray(TS_2_2_5, dims='time')\n",
    "        TS_2_2_5 = TS_2_2_5.rename(\"TS_2_2_5\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -14 cm\n",
    "    try:\n",
    "        TS_2_1_5 = ds['temp_10'].rename(\"TS_2_1_5\")\n",
    "    except KeyError:\n",
    "        TS_2_1_5 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_5 = xr.DataArray(TS_2_1_5, dims='time')\n",
    "        TS_2_1_5 = TS_2_1_5.rename(\"TS_2_1_5\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -34.3 cm\n",
    "    try:\n",
    "        TS_2_2_6 = ds['temp_11'].rename(\"TS_2_2_6\")\n",
    "    except KeyError:\n",
    "        TS_2_2_6 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_2_6 = xr.DataArray(TS_2_2_6, dims='time')\n",
    "        TS_2_2_6 = TS_2_2_6.rename(\"TS_2_2_6\")\n",
    "\n",
    "    # Soil temperature from AMC probe depth -16.5 cm\n",
    "    try:\n",
    "        TS_2_1_6 = ds['temp_12'].rename(\"TS_2_1_6\")\n",
    "    except KeyError:\n",
    "        TS_2_1_6 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_2_1_6 = xr.DataArray(TS_2_1_6, dims='time')\n",
    "        TS_2_1_6 = TS_2_1_6.rename(\"TS_2_1_4\")\n",
    "\n",
    "    # Temperature averaging for probes (-14 to -16 cm) below ground surface.\n",
    "    # The code checks to verify the data exists and for the averaging. If the\n",
    "    # data is -9999, the value is multipled by zero.\n",
    "    count = 0\n",
    "    if TS_2_1_1[0] != -9999 and TS_2_1_1[30] != -9999:\n",
    "        TS_2_1_1 = TS_2_1_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_1 = TS_2_1_1*0\n",
    "\n",
    "    if TS_2_1_2[0] != -9999 and TS_2_1_2[30] != -9999:\n",
    "        TS_2_1_2 = TS_2_1_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_2 = TS_2_1_2*0\n",
    "\n",
    "    if TS_2_1_3[0] != -9999 and TS_2_1_3[30] != -9999:\n",
    "        TS_2_1_3 = TS_2_1_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_3 = TS_2_1_3*0\n",
    "\n",
    "    if TS_2_1_4[0] != -9999 and TS_2_1_4[30] != -9999:\n",
    "        TS_2_1_4 = TS_2_1_4\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_4 = TS_2_1_4*0\n",
    "\n",
    "    if TS_2_1_5[0] != -9999 and TS_2_1_5[30] != -9999:\n",
    "        TS_2_1_5 = TS_2_1_5\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_5 = TS_2_1_5*0\n",
    "\n",
    "    if TS_2_1_6[0] != -9999 and TS_2_1_6[30] != -9999:\n",
    "        TS_2_1_6 = TS_2_1_6\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_1_6 = TS_2_1_6*0\n",
    "\n",
    "    # The averaging is done here and then renames the variable in xarray.\n",
    "    TS_2_1_A = (TS_2_1_1 + TS_2_1_2 + TS_2_1_3 + TS_2_1_4 +\n",
    "                TS_2_1_5 + TS_2_1_6)/count\n",
    "    TS_2_1_A = TS_2_1_A.rename(\"TS_2_1_A\")\n",
    "\n",
    "    # Temperature averaging for probes below -30 cm. Same averaging method\n",
    "    # is applied here as previous steps.\n",
    "    count = 0\n",
    "    if TS_2_2_1[0] != -9999 and TS_2_2_1[30] != -9999:\n",
    "        TS_2_2_1 = TS_2_2_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_2_1 = TS_2_2_1*0\n",
    "\n",
    "    if TS_2_2_2[0] != -9999 and TS_2_2_2[30] != -9999:\n",
    "        TS_2_2_2 = TS_2_2_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_3_2 = TS_2_2_2*0\n",
    "\n",
    "    if TS_2_2_3[0] != -9999 and TS_2_2_3[30] != -9999:\n",
    "        TS_2_2_3 = TS_2_2_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_2_3 = TS_2_2_3*0\n",
    "\n",
    "    if TS_2_2_4[0] != -9999 and TS_2_2_4[30] != -9999:\n",
    "        TS_2_2_4 = TS_2_2_4\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_2_4 = TS_2_2_4*0\n",
    "\n",
    "    if TS_2_2_5[0] != -9999 and TS_2_2_5[30] != -9999:\n",
    "        TS_2_2_5 = TS_2_2_5\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_2_5 = TS_2_2_5*0\n",
    "\n",
    "    if TS_2_2_6[0] != -9999 and TS_2_2_6[30] != -9999:\n",
    "        TS_2_2_6 = TS_2_2_6\n",
    "        count = count+1\n",
    "    else:\n",
    "        TS_2_2_6 = TS_2_2_6*0\n",
    "\n",
    "    # Averaging and renaming the variable.\n",
    "    TS_2_2_A = (TS_2_2_1 + TS_2_2_2 + TS_2_2_3 + TS_2_2_4 + TS_2_2_5 +\n",
    "                TS_2_2_6)/count\n",
    "    TS_2_2_A = TS_2_2_A.rename(\"TS_2_2_A\")\n",
    "\n",
    "    # Photosynthetic photon flux density, incoming\n",
    "    try:\n",
    "        PPFD_IN = ds['par_inc'].rename(\"PPFD_IN\")\n",
    "    except KeyError:\n",
    "        PPFD_IN = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        PPFD_IN = xr.DataArray(PPFD_IN, dims='time')\n",
    "        PPFD_IN = PPFD_IN.rename(\"PPFD_IN\")\n",
    "\n",
    "    # Photosynthetic photon flux density, outgoing\n",
    "    try:\n",
    "        PPFD_OUT = ds['par_ref'].rename(\"PPFD_OUT\")\n",
    "    except KeyError:\n",
    "        PPFD_OUT = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        PPFD_OUT = xr.DataArray(PPFD_OUT, dims='time')\n",
    "        PPFD_OUT = PPFD_OUT.rename(\"PPFD_OUT\")\n",
    "\n",
    "    # Soil water content (volumetric), range 0-100\n",
    "    # Soil water content at -36.8 cm\n",
    "    try:\n",
    "        SWC_1_2_1 = ds['vwc_1'].rename(\"SWC_1_2_1\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_1 = xr.DataArray(SWC_1_2_1, dims='time')\n",
    "        SWC_1_2_1 = SWC_1_2_1.rename(\"SWC_1_2_1\")\n",
    "\n",
    "    # Soil water content at -14 cm\n",
    "    try:\n",
    "        SWC_1_1_1 = ds['vwc_2'].rename(\"SWC_1_1_1\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_1 = xr.DataArray(SWC_1_1_1, dims='time')\n",
    "        SWC_1_1_1 = SWC_1_1_1.rename(\"SWC_1_1_1\")\n",
    "\n",
    "    # Soil water content at -35.6 cm\n",
    "    try:\n",
    "        SWC_1_2_2 = ds['vwc_3'].rename(\"SWC_1_2_2\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_2 = xr.DataArray(SWC_1_2_2, dims='time')\n",
    "        SWC_1_2_2 = SWC_1_2_2.rename(\"SWC_1_2_2\")\n",
    "\n",
    "    # Soil water content at -14 cm\n",
    "    try:\n",
    "        SWC_1_1_2 = ds['vwc_4'].rename(\"SWC_1_1_2\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_2 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_2 = xr.DataArray(SWC_1_1_2, dims='time')\n",
    "        SWC_1_1_2 = SWC_1_1_2.rename(\"SWC_1_1_2\")\n",
    "\n",
    "    # Soil water content at -35.6 cm\n",
    "    try:\n",
    "        SWC_1_2_3 = ds['vwc_5'].rename(\"SWC_1_2_3\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_3 = xr.DataArray(SWC_1_2_3, dims='time')\n",
    "        SWC_1_2_3 = SWC_1_2_3.rename(\"SWC_1_2_3\")\n",
    "\n",
    "    # Soil water content at -14 cm\n",
    "    try:\n",
    "        SWC_1_1_3 = ds['vwc_6'].rename(\"SWC_1_1_3\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_3 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_3 = xr.DataArray(SWC_1_1_3, dims='time')\n",
    "        SWC_1_1_3 = SWC_1_1_3.rename(\"SWC_1_1_3\")\n",
    "\n",
    "    # Soil water content at -34.3 cm\n",
    "    try:\n",
    "        SWC_1_2_4 = ds['vwc_7'].rename(\"SWC_1_2_4\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_4 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_4 = xr.DataArray(SWC_1_2_4, dims='time')\n",
    "        SWC_1_2_4 = SWC_1_2_4.rename(\"SWC_1_2_4\")\n",
    "\n",
    "    # Soil water content at -15.2 cm\n",
    "    try:\n",
    "        SWC_1_1_4 = ds['vwc_8'].rename(\"SWC_1_1_4\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_4 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_4 = xr.DataArray(SWC_1_1_4, dims='time')\n",
    "        SWC_1_1_4 = SWC_1_1_4.rename(\"SWC_1_1_4\")\n",
    "\n",
    "    # Soil water content at -34.9 cm\n",
    "    try:\n",
    "        SWC_1_2_5 = ds['vwc_9'].rename(\"SWC_1_2_5\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_5 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_5 = xr.DataArray(SWC_1_2_5, dims='time')\n",
    "        SWC_1_2_5 = SWC_1_2_5.rename(\"SWC_1_2_5\")\n",
    "\n",
    "    # Soil water content at -14 cm\n",
    "    try:\n",
    "        SWC_1_1_5 = ds['vwc_10'].rename(\"SWC_1_1_5\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_5 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_5 = xr.DataArray(SWC_1_1_5, dims='time')\n",
    "        SWC_1_1_5 = SWC_1_1_5.rename(\"SWC_1_1_5\")\n",
    "\n",
    "    # Soil water content at -34.3 cm\n",
    "    try:\n",
    "        SWC_1_2_6 = ds['vwc_11'].rename(\"SWC_1_2_6\")\n",
    "    except KeyError:\n",
    "        SWC_1_2_6 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_2_6 = xr.DataArray(SWC_1_2_6, dims='time')\n",
    "        SWC_1_2_6 = SWC_1_2_6.rename(\"SWC_1_2_6\")\n",
    "\n",
    "    # Soil water content at -16.5 cm\n",
    "    try:\n",
    "        SWC_1_1_6 = ds['vwc_12'].rename(\"SWC_1_1_6\")\n",
    "    except KeyError:\n",
    "        SWC_1_1_6 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        SWC_1_1_6 = xr.DataArray(SWC_1_1_6, dims='time')\n",
    "        SWC_1_1_6 = SWC_1_1_6.rename(\"SWC_1_1_6\")\n",
    "\n",
    "    # Soil water content averaging for probes closer (-14 to -16 cm)\n",
    "    # to ground surface.\n",
    "    count = 0\n",
    "    if SWC_1_1_1[0] != -9999 and SWC_1_1_1[30] != -9999:\n",
    "        SWC_1_1_1 = SWC_1_1_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1 = SWC_1_1_1*0\n",
    "\n",
    "    if SWC_1_1_2[0] != -9999 and SWC_1_1_2[30] != -9999:\n",
    "        SWC_1_1_2 = SWC_1_1_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1_2 = SWC_1_1_2*0\n",
    "\n",
    "    if SWC_1_1_3[0] != -9999 and SWC_1_1_3[30] != -9999:\n",
    "        SWC_1_1_3 = SWC_1_1_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1_3 = SWC_1_1_3*0\n",
    "\n",
    "    if SWC_1_1_4[0] != -9999 and SWC_1_1_4[30] != -9999:\n",
    "        SWC_1_1_4 = SWC_1_1_4\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1_4 = SWC_1_1_4*0\n",
    "\n",
    "    if SWC_1_1_5[0] != -9999 and SWC_1_1_5[30] != -9999:\n",
    "        SWC_1_1_5 = SWC_1_1_5\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1_5 = SWC_1_1_5*0\n",
    "\n",
    "    if SWC_1_1_6[0] != -9999 and SWC_1_1_6[30] != -9999:\n",
    "        SWC_1_1_6 = SWC_1_1_6\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_1_6 = SWC_1_1_6*0\n",
    "\n",
    "    # Averaging equation for soil water content.\n",
    "    SWC_1_1_A = (SWC_1_1_1 + SWC_1_1_2 + SWC_1_1_3 +\n",
    "                 SWC_1_1_4 + SWC_1_1_5 + SWC_1_1_6)/count\n",
    "    SWC_1_1_A = SWC_1_1_A.rename(\"SWC_1_1_A\")\n",
    "\n",
    "    # Soil water content averaging for probes between -34.0 cm and -36.0 cm.\n",
    "    count = 0\n",
    "    if SWC_1_2_1[0] != -9999 and SWC_1_2_1[30] != -9999:\n",
    "        SWC_1_2_1 = SWC_1_2_1\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_1 = SWC_1_2_1*0\n",
    "\n",
    "    if SWC_1_2_2[0] != -9999 and SWC_1_2_2[30] != -9999:\n",
    "        SWC_1_2_2 = SWC_1_2_2\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_2 = SWC_1_2_2*0\n",
    "\n",
    "    if SWC_1_2_3[0] != -9999 and SWC_1_2_3[30] != -9999:\n",
    "        SWC_1_2_3 = SWC_1_2_3\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_3 = SWC_1_2_3*0\n",
    "\n",
    "    if SWC_1_2_4[0] != -9999 and SWC_1_2_4[30] != -9999:\n",
    "        SWC_1_2_4 = SWC_1_2_4\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_4 = SWC_1_2_4*0\n",
    "\n",
    "    if SWC_1_2_5[0] != -9999 and SWC_1_2_5[30] != -9999:\n",
    "        SWC_1_2_5 = SWC_1_2_5\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_5 = SWC_1_2_5*0\n",
    "\n",
    "    if SWC_1_2_6[0] != -9999 and SWC_1_2_6[30] != -9999:\n",
    "        SWC_1_2_6 = SWC_1_2_6\n",
    "        count = count+1\n",
    "    else:\n",
    "        SWC_1_2_6 = SWC_1_2_6*0\n",
    "\n",
    "    # Averaging equation for soil water content\n",
    "    SWC_1_2_A = (SWC_1_2_1 + SWC_1_2_2 + SWC_1_2_3 +\n",
    "                 SWC_1_2_4 + SWC_1_2_5 + SWC_1_2_6)/count\n",
    "    SWC_1_2_A = SWC_1_2_A.rename(\"SWC_1_2_A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4ca58",
   "metadata": {},
   "source": [
    "Stamp data without the precipitation variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0893c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Soil temperature from the west profile 5 cm depth.\n",
    "    try:\n",
    "        TS_3_1_1 = ds['soil_temperature_west'][:, 0].rename(\n",
    "            'TS_3_1_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_3_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_3_1_1 = xr.DataArray(TS_3_1_1, dims='time')\n",
    "        TS_3_1_1 = TS_3_1_1.rename(\"TS_3_1_1\")\n",
    "\n",
    "    # Soil temperatuer from the west profile for 10 cm depth.\n",
    "    try:\n",
    "        TS_3_2_1 = ds['soil_temperature_west'][:, 1].rename(\n",
    "            'TS_3_2_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_3_2_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_3_2_1 = xr.DataArray(TS_3_2_1, dims='time')\n",
    "        TS_3_2_1 = TS_3_2_1.rename(\"TS_3_2_1\")\n",
    "\n",
    "    # Soil temperatuer from the west profile for 20 cm depth.\n",
    "    try:\n",
    "        TS_3_3_1 = ds['soil_temperature_west'][:, 2].rename(\n",
    "            'TS_3_3_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_3_3_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_3_3_1 = xr.DataArray(TS_3_3_1, dims='time')\n",
    "        TS_3_3_1 = TS_3_3_1.rename(\"TS_3_3_1\")\n",
    "\n",
    "    # Soil temperatuer from the west profile for 50 cm depth.\n",
    "    try:\n",
    "        TS_3_4_1 = ds['soil_temperature_west'][:, 3].rename(\n",
    "            'TS_3_4_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_3_4_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_3_4_1 = xr.DataArray(TS_3_4_1, dims='time')\n",
    "        TS_3_4_1 = TS_3_4_1.rename(\"TS_3_4_1\")\n",
    "\n",
    "    # Soil temperatuer from the west profile for 100 cm depth.\n",
    "    try:\n",
    "        TS_3_5_1 = ds['soil_temperature_west'][:, 4].rename(\n",
    "            'TS_3_5_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_3_5_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_3_5_1 = xr.DataArray(TS_3_5_1, dims='time')\n",
    "        TS_3_5_1 = TS_3_5_1.rename(\"TS_3_5_1\")\n",
    "\n",
    "    # Soil temperature from the eat profile 5 cm depth.\n",
    "    try:\n",
    "        TS_4_1_1 = ds['soil_temperature_east'][:, 0].rename(\n",
    "            'TS_4_1_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_4_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_4_1_1 = xr.DataArray(TS_4_1_1, dims='time')\n",
    "        TS_4_1_1 = TS_4_1_1.rename(\"TS_4_1_1\")\n",
    "\n",
    "    # Soil temperatuer from the east profile for 10 cm depth.\n",
    "    try:\n",
    "        TS_4_2_1 = ds['soil_temperature_east'][:, 1].rename(\n",
    "            'TS_4_2_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_4_2_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_4_2_1 = xr.DataArray(TS_4_2_1, dims='time')\n",
    "        TS_4_2_1 = TS_4_2_1.rename(\"TS_4_2_1\")\n",
    "\n",
    "    # Soil temperatuer from the east profile for 20 cm depth.\n",
    "    try:\n",
    "        TS_4_3_1 = ds['soil_temperature_west'][:, 2].rename(\n",
    "            'TS_4_3_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_4_3_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_4_3_1 = xr.DataArray(TS_4_3_1, dims='time')\n",
    "        TS_4_3_1 = TS_4_3_1.rename(\"TS_4_3_1\")\n",
    "\n",
    "    # Soil temperatuer from the east profile for 50 cm depth.\n",
    "    try:\n",
    "        TS_4_4_1 = ds['soil_temperature_west'][:, 3].rename(\n",
    "            'TS_4_4_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_4_4_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_4_4_1 = xr.DataArray(TS_4_4_1, dims='time')\n",
    "        TS_4_4_1 = TS_4_4_1.rename(\"TS_4_4_1\")\n",
    "\n",
    "    # Soil temperatuer from the east profile for 100 cm depth.\n",
    "    try:\n",
    "        TS_4_5_1 = ds['soil_temperature_west'][:, 4].rename(\n",
    "            'TS_4_5_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_4_5_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_4_5_1 = xr.DataArray(TS_4_5_1, dims='time')\n",
    "        TS_4_5_1 = TS_4_5_1.rename(\"TS_4_5_1\")\n",
    "\n",
    "    # Soil temperature from the south profile 5 cm depth.\n",
    "    try:\n",
    "        TS_5_1_1 = ds['soil_temperature_south'][:, 0].rename(\n",
    "            'TS_5_1_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_5_1_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_5_1_1 = xr.DataArray(TS_5_1_1, dims='time')\n",
    "        TS_5_1_1 = TS_5_1_1.rename(\"TS_5_1_1\")\n",
    "\n",
    "    # Soil temperatuer from the south profile for 10 cm depth.\n",
    "    try:\n",
    "        TS_5_2_1 = ds['soil_temperature_south'][:, 1].rename(\n",
    "            'TS_5_2_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_5_2_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_5_2_1 = xr.DataArray(TS_5_2_1, dims='time')\n",
    "        TS_5_2_1 = TS_5_2_1.rename(\"TS_5_2_1\")\n",
    "\n",
    "    # Soil temperatuer from the south profile for 20 cm depth.\n",
    "    try:\n",
    "        TS_5_3_1 = ds['soil_temperature_south'][:, 2].rename(\n",
    "            'TS_5_3_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_5_3_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_5_3_1 = xr.DataArray(TS_5_3_1, dims='time')\n",
    "        TS_5_3_1 = TS_5_3_1.rename(\"TS_5_3_1\")\n",
    "\n",
    "    # Soil temperatuer from the west profile for 50 cm depth.\n",
    "    try:\n",
    "        TS_5_4_1 = ds['soil_temperature_south'][:, 3].rename(\n",
    "            'TS_5_4_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_5_4_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_5_4_1 = xr.DataArray(TS_5_4_1, dims='time')\n",
    "        TS_5_4_1 = TS_5_4_1.rename(\"TS_5_4_1\")\n",
    "\n",
    "    # Soil temperatuer from the south profile for 100 cm depth.\n",
    "    try:\n",
    "        TS_5_5_1 = ds['soil_temperature_south'][:, 4].rename(\n",
    "            'TS_5_5_1').drop_vars('depth')\n",
    "    except KeyError:\n",
    "        TS_5_5_1 = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        TS_5_5_1 = xr.DataArray(TS_5_5_1, dims='time')\n",
    "        TS_5_5_1 = TS_5_5_1.rename(\"TS_5_5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde4e30",
   "metadata": {},
   "source": [
    "Stamppcp variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04ed19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 30 minute averaged precipitation data in mm.\n",
    "    try:\n",
    "        P = ds['precip'].rename('P')\n",
    "    except KeyError:\n",
    "        P = np.ones((TIMESTAMP_END.shape))*-9999\n",
    "        P = xr.DataArray(P, dims='time')\n",
    "        P = P.rename(\"P\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da266620",
   "metadata": {},
   "source": [
    "# Writing the data out to a CSV file\n",
    "All the data will be converted into a dataframe subset to allow us to out it to a csv with the naming convention of our choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d0a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_subset = [TIMESTAMP_START, TIMESTAMP_END, FC, CO2, CO2_MIXING_RATIO,\n",
    "                 H2O, H2O_MIXING_RATIO, CH4, CH4_MIXING_RATIO, TAU, H, LE, TA,\n",
    "                 PA, RH, T_SONIC, VPD, MO_LENGTH, ZL, WS, WD, USTAR, WS_MAX,\n",
    "                 SW_IN, SW_OUT, LW_IN, LW_OUT, ALB, NETRAD, P, G_1_1_1,\n",
    "                 G_1_1_2, G_1_1_3, G_1_1_A, TS_1_1_1, TS_1_1_2, TS_1_1_3,\n",
    "                 TS_1_1_A, TS_2_1_1, TS_2_1_2, TS_2_1_3, TS_2_1_4, TS_2_1_5,\n",
    "                 TS_2_1_6, TS_2_1_A, TS_2_2_1, TS_2_2_2, TS_2_2_3, TS_2_2_4,\n",
    "                 TS_2_2_5, TS_2_2_6, TS_2_2_A, TS_3_1_1, TS_3_2_1, TS_3_3_1,\n",
    "                 TS_3_4_1, TS_3_5_1, TS_4_1_1, TS_4_2_1, TS_4_3_1, TS_4_4_1,\n",
    "                 TS_4_5_1, TS_5_1_1, TS_5_2_1, TS_5_3_1, TS_5_4_1, TS_5_5_1,\n",
    "                 PPFD_IN, PPFD_OUT, SWC_1_1_1, SWC_1_1_2, SWC_1_1_3, SWC_1_1_4,\n",
    "                 SWC_1_1_5, SWC_1_1_6, SWC_1_1_A, SWC_1_2_1, SWC_1_2_2,\n",
    "                 SWC_1_2_3, SWC_1_2_4, SWC_1_2_5, SWC_1_2_6, SWC_1_2_A, ]\n",
    "\n",
    "    ds_out = xr.Dataset()\n",
    "    for dataarray in df_subset:\n",
    "        ds_out = xr.merge([ds_out, dataarray.to_dataset()])\n",
    "\n",
    "    df_out = ds_out.to_dataframe()\n",
    "\n",
    "    df_out.to_csv(Ameriflux_name + '_'+'HH_'+str(df_out['TIMESTAMP_START'][0])\n",
    "                  + '_' + str(df_out['TIMESTAMP_END'][47])+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c50af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
